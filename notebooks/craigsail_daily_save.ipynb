{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrates the use of craigsail_search Boats() class.\n",
    "\n",
    "To do your own search, add your search category as show below. Gather raw data and use pandas to clean / process the data. \n",
    "Once you have figured out how to process the fields in your data, combine the functionality in a def and add it to craigsail_search by subclassing the Search() class. If you have any generic functions that can apply to any data, add them to the Search class.\n",
    "\n",
    "CraigslistForSale.show_filters(category='boo')\n",
    "Get category codes from craigslist.com by clicking on the desired sale category and looking in the url address.\n",
    "\n",
    "Example: https://gainesville.craigslist.org/d/boats/search/boo - use the 'boo' at the end of the url\n",
    "\n",
    "TODO: for 1k page limit / day, simply break cities up into separate calls using VPN switch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.11 ('proximate')' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'conda install -n proximate ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import geopandas as gpd \n",
    "from craigslist import CraigslistForSale\n",
    "sys.path.append('../')\n",
    "from craigsail_search import Boats, Bikes\n",
    "\n",
    "pd.set_option('max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up your search paramaters \n",
    "Get more filters by looking at API documentation linked to above, or do a simple seach on a city and see which fields are returned / available for paramaters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sailboats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = {'query':'Sailboat', # set your boat query here\n",
    "            'search_titles':True,\n",
    "            # 'has_image':True, # not necessary if you're just tracking elements for price movements and inventory quantity\n",
    "            'bundle_duplicates':True,\n",
    "            #'boat_propulsion_type':'sail'\n",
    "          }\n",
    "\n",
    "\n",
    "port_cities = ['dallas','galveston','houston', # TX\n",
    "               'seattle','olympic','skagit', # WA\n",
    "                'micronesia','houma','caribbean','puertorico','virgin','mobile', # INTL\n",
    "                'losangeles','monterey','sandiego','sfbay','oregoncoast', # CA\n",
    "                'washingtondc', # D.C.\n",
    "               'daytona','keys','miami','fortmyers','jacksonville','miami','panamacity','pensacola','sarasota','staugustine','tampa', # FL\n",
    "                'jerseyshore','newyork', # NJ/NY\n",
    "               'outerbanks', # NC\n",
    "                'portland', # OR\n",
    "               'hiltonhead','myrtlebeach','charleston', # SC\n",
    "                'neworleans', # LA\n",
    "                'brunswick','savannah','statesboro'] # GA\n",
    "\n",
    "nearby_cities = [ 'asheville','eastnc', 'boone','hickory','greensboro','raleigh','fayetteville', 'wilmington', 'tricities', 'winstonsalem', 'onslow', # NC\n",
    "                 'columbia', 'florence','greenville', # SC\n",
    "                 'atlanta', 'augusta', 'athens','macon', 'albany', 'valdosta', 'nwga', # GA\n",
    "                 'tallahassee', 'lakecity', 'gainesville', 'ocala', # FL\n",
    "                'chattanooga', 'knoxville', # TN\n",
    "                ] \n",
    "\n",
    "\n",
    "all_cities = port_cities + nearby_cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate your search object and perform the search by calling the prep method\n",
    "Depending on the number of cities, download could take several minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with your local machine path\n",
    "data_path = '/Users/destin/Documents/LOCALHOST/DEVELOPMENT/CraigSail/data' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "craigslist_sailboats = Boats('boo', data_path, *all_cities, **filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../craigsail_search.py:235: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  years = df['name'].str.strip().str.extract(r'(?P<Year>\\s{0,1}[1-2]\\d{2,3}\\s*)')\n",
      "../craigsail_search.py:237: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # df[col] = pd.to_datetime(df[col]).dt.year\n",
      "../craigsail_search.py:233: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  for col in df.columns:\n",
      "../craigsail_search.py:239: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].str.replace('\\$|,', '').astype(float)\n",
      "../craigsail_search.py:241: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(int)\n",
      "../craigsail_search.py:230: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # \t\t\t\t'engine hours (total)',\n"
     ]
    }
   ],
   "source": [
    "download_time, sailboats_df = craigslist_sailboats.prep_daily_sailboats_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Download took: 7.27 minutes. 746 records gathered.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Download took: {round(download_time.seconds/60, 2)} minutes. {sailboats_df.index.size} records gathered.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>repost_of</th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "      <th>datetime</th>\n",
       "      <th>last_updated_2020-04-05</th>\n",
       "      <th>price_2020-04-05</th>\n",
       "      <th>where</th>\n",
       "      <th>has_image</th>\n",
       "      <th>geotag</th>\n",
       "      <th>body</th>\n",
       "      <th>created</th>\n",
       "      <th>images</th>\n",
       "      <th>condition</th>\n",
       "      <th>boat_propulsion_type</th>\n",
       "      <th>city</th>\n",
       "      <th>length overall (LOA)</th>\n",
       "      <th>model name / number</th>\n",
       "      <th>propulsion type</th>\n",
       "      <th>make / manufacturer</th>\n",
       "      <th>year manufactured</th>\n",
       "      <th>engine hours (total)</th>\n",
       "      <th>longitud total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7103346948</td>\n",
       "      <td>6636125352</td>\n",
       "      <td>Beautiful Mahogany Sunfish Sailboat</td>\n",
       "      <td>https://dallas.craigslist.org/dal/boa/d/lewisv...</td>\n",
       "      <td>2020-04-04 09:50:00</td>\n",
       "      <td>2020-04-04 09:50:00</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>Lewisville, TX</td>\n",
       "      <td>True</td>\n",
       "      <td>(33.069644, -97.01752)</td>\n",
       "      <td>Classic Christmas Special\\n\\nBeautiful Classic...</td>\n",
       "      <td>2020-04-04 09:46:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>good</td>\n",
       "      <td>sail</td>\n",
       "      <td>dallas</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Sunfish</td>\n",
       "      <td>sail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7101311774</td>\n",
       "      <td>6873639086</td>\n",
       "      <td>AMF Apollo Sailboat</td>\n",
       "      <td>https://dallas.craigslist.org/ndf/boa/d/wylie-...</td>\n",
       "      <td>2020-03-30 20:25:00</td>\n",
       "      <td>2020-03-30 20:25:00</td>\n",
       "      <td>900.0</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>(33.0041, -96.5394)</td>\n",
       "      <td>I am helping my dad sell his 1980 AMF Apollo t...</td>\n",
       "      <td>2020-03-30 20:21:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sail</td>\n",
       "      <td>dallas</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sail</td>\n",
       "      <td>AMF Apollo</td>\n",
       "      <td>1980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id   repost_of                                 name  \\\n",
       "0  7103346948  6636125352  Beautiful Mahogany Sunfish Sailboat   \n",
       "1  7101311774  6873639086                  AMF Apollo Sailboat   \n",
       "\n",
       "                                                 url            datetime  \\\n",
       "0  https://dallas.craigslist.org/dal/boa/d/lewisv... 2020-04-04 09:50:00   \n",
       "1  https://dallas.craigslist.org/ndf/boa/d/wylie-... 2020-03-30 20:25:00   \n",
       "\n",
       "  last_updated_2020-04-05  price_2020-04-05           where  has_image  \\\n",
       "0     2020-04-04 09:50:00            2500.0  Lewisville, TX       True   \n",
       "1     2020-03-30 20:25:00             900.0            None       True   \n",
       "\n",
       "                   geotag                                               body  \\\n",
       "0  (33.069644, -97.01752)  Classic Christmas Special\\n\\nBeautiful Classic...   \n",
       "1     (33.0041, -96.5394)  I am helping my dad sell his 1980 AMF Apollo t...   \n",
       "\n",
       "              created images condition boat_propulsion_type    city  \\\n",
       "0 2020-04-04 09:46:00     []      good                 sail  dallas   \n",
       "1 2020-03-30 20:21:00     []       NaN                 sail  dallas   \n",
       "\n",
       "   length overall (LOA) model name / number propulsion type  \\\n",
       "0                  13.0             Sunfish            sail   \n",
       "1                  16.0                 NaN            sail   \n",
       "\n",
       "  make / manufacturer year manufactured  engine hours (total) longitud total  \n",
       "0                 NaN               NaN                   NaN            NaN  \n",
       "1          AMF Apollo              1980                   NaN            NaN  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an example of the data that is returned \n",
    "sailboats_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 746 entries, 0 to 745\n",
      "Data columns (total 23 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   id                       746 non-null    int64         \n",
      " 1   repost_of                353 non-null    object        \n",
      " 2   name                     746 non-null    object        \n",
      " 3   url                      746 non-null    object        \n",
      " 4   datetime                 746 non-null    datetime64[ns]\n",
      " 5   last_updated_2020-04-05  746 non-null    datetime64[ns]\n",
      " 6   price_2020-04-05         746 non-null    float64       \n",
      " 7   where                    680 non-null    object        \n",
      " 8   has_image                746 non-null    bool          \n",
      " 9   geotag                   733 non-null    object        \n",
      " 10  body                     746 non-null    object        \n",
      " 11  created                  745 non-null    datetime64[ns]\n",
      " 12  images                   746 non-null    object        \n",
      " 13  condition                553 non-null    object        \n",
      " 14  boat_propulsion_type     746 non-null    object        \n",
      " 15  city                     746 non-null    object        \n",
      " 16  length overall (LOA)     745 non-null    float64       \n",
      " 17  model name / number      456 non-null    object        \n",
      " 18  propulsion type          745 non-null    object        \n",
      " 19  make / manufacturer      576 non-null    object        \n",
      " 20  year manufactured        552 non-null    object        \n",
      " 21  engine hours (total)     216 non-null    float64       \n",
      " 22  longitud total           1 non-null      object        \n",
      "dtypes: bool(1), datetime64[ns](3), float64(3), int64(1), object(15)\n",
      "memory usage: 129.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# characteristics of the data returned\n",
    "sailboats_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean the data\n",
    "Note: If a class already exists for your search category and has cleaning methods, call them here. \n",
    "Otherwise, begin building the functionality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-3d382eaea388>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdaily_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcraigslist_sailboats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_city_sailboats_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdaily_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/LOCALHOST/DEVELOPMENT/CraigSail/craigsail_search.py\u001b[0m in \u001b[0;36mclean_city_sailboats_data\u001b[0;34m(self, df, clean_up)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0;31m#                               'condition']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'year manufactured'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# extract year from name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                                 \u001b[0myears\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'(?P<Year>\\s{0,1}[1-2]\\d{2,3}\\s*)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5268\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5269\u001b[0m         ):\n\u001b[0;32m-> 5270\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5271\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;31m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0maccessor_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;31m# Replace the property with the accessor object. Inspired by:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;31m# http://www.pydanny.com/cached-property.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferred_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_categorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"string\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m_validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   2096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2097\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minferred_dtype\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2098\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can only use .str accessor with string values!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2099\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "daily_cleaned = craigslist_sailboats.clean_city_sailboats_data(sailboats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_cols = ['repost_of', 'name', 'url', 'where', 'body', 'condition', 'boat_propulsion_type', 'make / manufacturer', 'propulsion type', 'model name / number']\n",
    "daily_cleaned[strip_cols] = craigslist_sailboats.clean_str_columns(daily_cleaned[strip_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_cleaned = craigslist_sailboats.strip_nan_columns(daily_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the data\n",
    "Go low-tech with .CSV files. More stable and easily replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suffix for unique file name\n",
    "today = pd.to_datetime('today').strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns for merging\n",
    "daily_df = daily_df.rename({'last_updated': 'last_updated_' + today, 'price': 'price_' + today}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df.to_csv(f'../data/all_boats_data {today}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = {'query':'touring', # set your boat query here\n",
    "            'search_titles':True,\n",
    "            # 'has_image':True, # not necessary if you're just tracking elements for price movements and inventory quantity\n",
    "            'bundle_duplicates':True,\n",
    "            #'boat_propulsion_type':'sail'\n",
    "          }\n",
    "\n",
    "nearby_cities = [ 'asheville','eastnc', 'boone','hickory','greensboro','raleigh','fayetteville', 'wilmington', 'tricities', 'winstonsalem', 'onslow', # NC\n",
    "                 'columbia', 'florence','greenville', 'hiltonhead','myrtlebeach','charleston',# SC\n",
    "                 'atlanta', 'augusta', 'athens','macon', 'albany', 'valdosta', 'nwga', 'brunswick','savannah','statesboro', # GA\n",
    "                 'tallahassee', 'lakecity', 'gainesville', 'ocala', # FL\n",
    "                'chattanooga', 'knoxville', # TN\n",
    "                ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate your search object and perform the search by calling the prep method\n",
    "Depending on the number of cities, download could take several minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with your local machine path\n",
    "data_path = '/Users/destin/Documents/LOCALHOST/DEVELOPMENT/CraigSail/data' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "craigslist_bikes = Bikes('bia', data_path, *nearby_cities, **filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_time, bikes_df = craigslist_bikes.get_all_daily_postings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'Download took: {round(download_time.seconds/60, 2)} minutes. {bikes_df.index.size} records gathered.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example of the data that is returned \n",
    "bikes_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# characteristics of the data returned\n",
    "bikes_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean the data\n",
    "Note: If a class already exists for your search category and has cleaning methods, call them here. \n",
    "Otherwise, begin building the functionality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-3d382eaea388>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdaily_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcraigslist_sailboats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_city_sailboats_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdaily_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/LOCALHOST/DEVELOPMENT/CraigSail/craigsail_search.py\u001b[0m in \u001b[0;36mclean_city_sailboats_data\u001b[0;34m(self, df, clean_up)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0;31m#                               'condition']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'year manufactured'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# extract year from name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                                 \u001b[0myears\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'(?P<Year>\\s{0,1}[1-2]\\d{2,3}\\s*)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5268\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5269\u001b[0m         ):\n\u001b[0;32m-> 5270\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5271\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;31m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0maccessor_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;31m# Replace the property with the accessor object. Inspired by:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;31m# http://www.pydanny.com/cached-property.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferred_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_categorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"string\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m_validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   2096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2097\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minferred_dtype\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2098\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can only use .str accessor with string values!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2099\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "daily_cleaned = craigslist_bikes.clean_city_sailboats_data(bikes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_cols = ['repost_of', 'name', 'url', 'where', 'body', 'condition', 'boat_propulsion_type', 'make / manufacturer', 'propulsion type', 'model name / number']\n",
    "daily_cleaned[strip_cols] = craigslist_sailboats.clean_str_columns(daily_cleaned[strip_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_cleaned = craigslist_sailboats.strip_nan_columns(daily_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the data\n",
    "Go low-tech with .CSV files. More stable and easily replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suffix for unique file name\n",
    "today = pd.to_datetime('today').strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns for merging\n",
    "daily_df = daily_df.rename({'last_updated': 'last_updated_' + today, 'price': 'price_' + today}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df.to_csv(f'../data/all_boats_data {today}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9cb35de1a27524ad1753e63af46f7cb82eb25e358e1b22272413c296c673bee7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('proximate')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
